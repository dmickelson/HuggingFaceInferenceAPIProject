{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNrkofU1nWDsubYen/30xlo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmickelson/HuggingFaceInferenceAPIProject/blob/main/idm_vton_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook to test conenctions with HuggingFace IDM VTON Using Transformers"
      ],
      "metadata": {
        "id": "ztXXSbaTCW1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Have to set your HF token 'HF_TOKEN' in colab secret*"
      ],
      "metadata": {
        "id": "qkRdHBXEOx48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the VITON-HD GITHUB repository into notebook for integration testing."
      ],
      "metadata": {
        "id": "rasd_5i5KFir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/shadow2496/VITON-HD.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35XLbxJ7Kue5",
        "outputId": "6a2bffb4-b485-45b5-ad3f-d2f5310af1fe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VITON-HD'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 46 (delta 8), reused 7 (delta 6), pack-reused 31 (from 1)\u001b[K\n",
            "Receiving objects: 100% (46/46), 5.03 MiB | 23.09 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Installs required libraries using `pip install` for transformers, torch, torchvision, torchgeometry, and diffusers."
      ],
      "metadata": {
        "id": "DcjfpiBn3nLR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVOJc9fzCPW3",
        "outputId": "d55146d0-ffbc-42c2-f4d8-0328de0d1bf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Collecting torchgeometry\n",
            "  Downloading torchgeometry-0.1.2-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading torchgeometry-0.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m73.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchgeometry\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 torchgeometry-0.1.2\n",
            "Collecting diffusers\n",
            "  Downloading diffusers-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.23.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.7.4)\n",
            "Downloading diffusers-0.30.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diffusers\n",
            "Successfully installed diffusers-0.30.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torch torchvision torchgeometry\n",
        "!pip install diffusers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Rename the downloaded \"VITON-HD\" repo to remove '-' dash. The new folder name is \"VITONHD\"\n",
        "- Does this for easier python module import which doesnt like dashes."
      ],
      "metadata": {
        "id": "xNp7jYUKMtUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.rename(\"VITON-HD\", \"VITONHD\")"
      ],
      "metadata": {
        "id": "5r-jJ99oM8Ki"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Get the necessary test files into the proper location.\n",
        "- Copy files from the shared Google Drive.\n",
        "- Uses the `gdown` library to download the data and checkpoints from the provided URLs.\n",
        "- Unzips the testing files for the data processing. Unzips the file in the datasets folder."
      ],
      "metadata": {
        "id": "a9oq42j1b_bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "!ls /content/\n",
        "os.chdir('/content/VITONHD')\n",
        "print(f'CWD: {os.getcwd()}')\n",
        "import gdown\n",
        "# Shared Checkpoint drive URL\n",
        "checkpoints_url = \"https://drive.google.com/drive/folders/0B8kXrnobEVh9flZvVVViOTVSZmZJV09yckNlM1Z4bG05LW4xSTl0R2hLTjFoRllhQ0t0RFE?resourcekey=0-629_3FRyq11k3PF3RUFJvw\"\n",
        "gdown.download_folder(checkpoints_url, quiet=False, use_cookies=False)\n",
        "# Shared Dataset drive URL\n",
        "datasets_url = \"https://drive.google.com/drive/folders/0B8kXrnobEVh9flBkdnNYR3V5dTNKQmFWNURXMUExZ0lFcngxeGI1WkdLT3p5Z1h0OTc2MjQ?resourcekey=0-l_xMCXpXAg7uU5xMZYuKXA\"\n",
        "gdown.download_folder(datasets_url, quiet=False, use_cookies=False)\n",
        "# Unzip the test.zip file from within the downloaded datasets\n",
        "os.chdir('/content/VITONHD/datasets')\n",
        "import zipfile\n",
        "zip_file_name = 'test.zip'\n",
        "with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "os.chdir('/content/VITONHD')\n",
        "print(f'CWD: {os.getcwd()}')\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJmhAjH_XyQg",
        "outputId": "109be59b-d23e-451a-9864-156cc990e334"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data  VITONHD\n",
            "assets\t     datasets\t  LICENSE      __pycache__  test.py\n",
            "checkpoints  datasets.py  networks.py  README.md    utils.py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1RM4OthSM6V4r7kWCu8SbPIPY14Oz8B2u alias_final.pth\n",
            "Processing file 1MBHBddaAs7sy8W40jzLmNL83AUh035F1 gmm_final.pth\n",
            "Processing file 17U1sooR3mVIbe8a7rZuFIF3kukPchHfZ seg_final.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1RM4OthSM6V4r7kWCu8SbPIPY14Oz8B2u\n",
            "From (redirected): https://drive.google.com/uc?id=1RM4OthSM6V4r7kWCu8SbPIPY14Oz8B2u&confirm=t&uuid=0bf1676b-e242-462a-acb0-450966836eae\n",
            "To: /content/VITONHD/checkpoints/alias_final.pth\n",
            "100%|██████████| 402M/402M [00:14<00:00, 27.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MBHBddaAs7sy8W40jzLmNL83AUh035F1\n",
            "To: /content/VITONHD/checkpoints/gmm_final.pth\n",
            "100%|██████████| 76.2M/76.2M [00:03<00:00, 21.3MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=17U1sooR3mVIbe8a7rZuFIF3kukPchHfZ\n",
            "From (redirected): https://drive.google.com/uc?id=17U1sooR3mVIbe8a7rZuFIF3kukPchHfZ&confirm=t&uuid=a8a9542b-a33b-4e05-8ddb-19bd79eb8d20\n",
            "To: /content/VITONHD/checkpoints/seg_final.pth\n",
            "100%|██████████| 138M/138M [00:05<00:00, 24.1MB/s]\n",
            "Download completed\n",
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1ncEHn_6liOot8sgt3A2DOFJBffvx8tW8 test_pairs.txt\n",
            "Processing file 1ZA2C8yMOprwc0TV4hvrt0X-ljZugrClq test.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ncEHn_6liOot8sgt3A2DOFJBffvx8tW8\n",
            "To: /content/VITONHD/datasets/test_pairs.txt\n",
            "100%|██████████| 156/156 [00:00<00:00, 646kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZA2C8yMOprwc0TV4hvrt0X-ljZugrClq\n",
            "To: /content/VITONHD/datasets/test.zip\n",
            "100%|██████████| 2.69M/2.69M [00:00<00:00, 226MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test  test_pairs.txt  test.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing the Model\n",
        "Import the required libraries:"
      ],
      "metadata": {
        "id": "F1ZLe66bDPfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torchgeometry as tgm\n",
        "\n",
        "from VITONHD.datasets import VITONDataset, VITONDataLoader\n",
        "from VITONHD.networks import SegGenerator, GMM, ALIASGenerator\n",
        "from VITONHD.utils import gen_noise, load_checkpoint, save_images\n"
      ],
      "metadata": {
        "id": "0t3Amb8SDRak"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create the get_opt function\n",
        "- The get_opt function defines the command-line arguments used to configure the test process. These arguments include:\n",
        "  - name: Name for the testing process (used for saving outputs).\n",
        "  - batch_size: Batch size for processing data.\n",
        "  - dataset_dir: Path to the directory containing the datasets.\n",
        "  - dataset_mode: Testing mode (e.g., \"test\").\n",
        "  - dataset_list: Path to a file listing test data pairs.\n",
        "  - checkpoint_dir: Path to the directory containing the model checkpoints.\n",
        "  - save_dir: Path to the directory for saving test results.\n",
        "  - And other arguments related to model configuration."
      ],
      "metadata": {
        "id": "BcCgF2N8DZuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_opt():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--name', type=str, required=True)\n",
        "\n",
        "    parser.add_argument('-b', '--batch_size', type=int, default=1)\n",
        "    parser.add_argument('-j', '--workers', type=int, default=1)\n",
        "    parser.add_argument('--load_height', type=int, default=1024)\n",
        "    parser.add_argument('--load_width', type=int, default=768)\n",
        "    parser.add_argument('--shuffle', action='store_true')\n",
        "\n",
        "    parser.add_argument('--dataset_dir', type=str, default='./datasets/')\n",
        "    parser.add_argument('--dataset_mode', type=str, default='test')\n",
        "    parser.add_argument('--dataset_list', type=str, default='test_pairs.txt')\n",
        "    parser.add_argument('--checkpoint_dir', type=str, default='./checkpoints/')\n",
        "    parser.add_argument('--save_dir', type=str, default='./results/')\n",
        "\n",
        "    parser.add_argument('--display_freq', type=int, default=1)\n",
        "\n",
        "    parser.add_argument('--seg_checkpoint', type=str, default='seg_final.pth')\n",
        "    parser.add_argument('--gmm_checkpoint', type=str, default='gmm_final.pth')\n",
        "    parser.add_argument('--alias_checkpoint', type=str, default='alias_final.pth')\n",
        "\n",
        "    # common\n",
        "    parser.add_argument('--semantic_nc', type=int, default=13, help='# of human-parsing map classes')\n",
        "    parser.add_argument('--init_type', choices=['normal', 'xavier', 'xavier_uniform', 'kaiming', 'orthogonal', 'none'], default='xavier')\n",
        "    parser.add_argument('--init_variance', type=float, default=0.02, help='variance of the initialization distribution')\n",
        "\n",
        "    # for GMM\n",
        "    parser.add_argument('--grid_size', type=int, default=5)\n",
        "\n",
        "    # for ALIASGenerator\n",
        "    parser.add_argument('--norm_G', type=str, default='spectralaliasinstance')\n",
        "    parser.add_argument('--ngf', type=int, default=64, help='# of generator filters in the first conv layer')\n",
        "    parser.add_argument('--num_upsampling_layers', choices=['normal', 'more', 'most'], default='most',\n",
        "                        help='If \\'more\\', add upsampling layer between the two middle resnet blocks. '\n",
        "                             'If \\'most\\', also add one more (upsampling + resnet) layer at the end of the generator.')\n",
        "\n",
        "    opt = parser.parse_args()\n",
        "    return opt"
      ],
      "metadata": {
        "id": "2KqWQqMvDegl"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Define the test function\n",
        "- The test function takes the parsed arguments (opt), the segmentation model (seg), the GMM model (gmm), and the Alias model (alias) as input.\n",
        "- It defines an upsampling layer, a Gaussian blur filter, and loads the testing dataset.\n",
        "- The function iterates through the test data loader and performs the following steps for each data item:\n",
        "  - Segmentation generation: It uses the segmentation model (seg) to predict human parsing maps from the input data.\n",
        "  - Clothes deformation: It uses the GMM model (gmm) to warp the clothes based on the pose and parsing information.\n",
        "  - Try-on synthesis: It uses the Alias model (alias) to generate the final image with the virtually tried-on clothes.\n",
        "- The function saves the generated images with names combining the image name and the name provided as an argument (test_1 in this example)."
      ],
      "metadata": {
        "id": "KSLAJijKP2cM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(opt, seg, gmm, alias):\n",
        "    up = nn.Upsample(size=(opt.load_height, opt.load_width), mode='bilinear')\n",
        "    gauss = tgm.image.GaussianBlur((15, 15), (3, 3))\n",
        "    gauss.cuda()\n",
        "\n",
        "    test_dataset = VITONDataset(opt)\n",
        "    test_loader = VITONDataLoader(opt, test_dataset)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, inputs in enumerate(test_loader.data_loader):\n",
        "            img_names = inputs['img_name']\n",
        "            c_names = inputs['c_name']['unpaired']\n",
        "\n",
        "            img_agnostic = inputs['img_agnostic'].cuda()\n",
        "            parse_agnostic = inputs['parse_agnostic'].cuda()\n",
        "            pose = inputs['pose'].cuda()\n",
        "            c = inputs['cloth']['unpaired'].cuda()\n",
        "            cm = inputs['cloth_mask']['unpaired'].cuda()\n",
        "\n",
        "            # Part 1. Segmentation generation\n",
        "            parse_agnostic_down = F.interpolate(parse_agnostic, size=(256, 192), mode='bilinear')\n",
        "            pose_down = F.interpolate(pose, size=(256, 192), mode='bilinear')\n",
        "            c_masked_down = F.interpolate(c * cm, size=(256, 192), mode='bilinear')\n",
        "            cm_down = F.interpolate(cm, size=(256, 192), mode='bilinear')\n",
        "            seg_input = torch.cat((cm_down, c_masked_down, parse_agnostic_down, pose_down, gen_noise(cm_down.size()).cuda()), dim=1)\n",
        "\n",
        "            parse_pred_down = seg(seg_input)\n",
        "            parse_pred = gauss(up(parse_pred_down))\n",
        "            parse_pred = parse_pred.argmax(dim=1)[:, None]\n",
        "\n",
        "            parse_old = torch.zeros(parse_pred.size(0), 13, opt.load_height, opt.load_width, dtype=torch.float).cuda()\n",
        "            parse_old.scatter_(1, parse_pred, 1.0)\n",
        "\n",
        "            labels = {\n",
        "                0:  ['background',  [0]],\n",
        "                1:  ['paste',       [2, 4, 7, 8, 9, 10, 11]],\n",
        "                2:  ['upper',       [3]],\n",
        "                3:  ['hair',        [1]],\n",
        "                4:  ['left_arm',    [5]],\n",
        "                5:  ['right_arm',   [6]],\n",
        "                6:  ['noise',       [12]]\n",
        "            }\n",
        "            parse = torch.zeros(parse_pred.size(0), 7, opt.load_height, opt.load_width, dtype=torch.float).cuda()\n",
        "            for j in range(len(labels)):\n",
        "                for label in labels[j][1]:\n",
        "                    parse[:, j] += parse_old[:, label]\n",
        "\n",
        "            # Part 2. Clothes Deformation\n",
        "            agnostic_gmm = F.interpolate(img_agnostic, size=(256, 192), mode='nearest')\n",
        "            parse_cloth_gmm = F.interpolate(parse[:, 2:3], size=(256, 192), mode='nearest')\n",
        "            pose_gmm = F.interpolate(pose, size=(256, 192), mode='nearest')\n",
        "            c_gmm = F.interpolate(c, size=(256, 192), mode='nearest')\n",
        "            gmm_input = torch.cat((parse_cloth_gmm, pose_gmm, agnostic_gmm), dim=1)\n",
        "\n",
        "            _, warped_grid = gmm(gmm_input, c_gmm)\n",
        "            warped_c = F.grid_sample(c, warped_grid, padding_mode='border')\n",
        "            warped_cm = F.grid_sample(cm, warped_grid, padding_mode='border')\n",
        "\n",
        "            # Part 3. Try-on synthesis\n",
        "            misalign_mask = parse[:, 2:3] - warped_cm\n",
        "            misalign_mask[misalign_mask < 0.0] = 0.0\n",
        "            parse_div = torch.cat((parse, misalign_mask), dim=1)\n",
        "            parse_div[:, 2:3] -= misalign_mask\n",
        "\n",
        "            output = alias(torch.cat((img_agnostic, pose, warped_c), dim=1), parse, parse_div, misalign_mask)\n",
        "\n",
        "            unpaired_names = []\n",
        "            for img_name, c_name in zip(img_names, c_names):\n",
        "                unpaired_names.append('{}_{}'.format(img_name.split('_')[0], c_name))\n",
        "\n",
        "            save_images(output, unpaired_names, os.path.join(opt.save_dir, opt.name))\n",
        "\n",
        "            if (i + 1) % opt.display_freq == 0:\n",
        "                print(\"step: {}\".format(i + 1))"
      ],
      "metadata": {
        "id": "7kPqQE0cP8WP"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Define the main function\n",
        "- The main function starts by parsing the command-line arguments using get_opt and prints the configuration.\n",
        "- It creates a directory to save the test results if it doesn't exist.\n",
        "- Three model instances are created for segmentation (seg), GMM (gmm), and Alias (alias) based on the specified configurations.\n",
        "- The script then loads the weights for each model from the corresponding checkpoint files.\n",
        "- Finally, it sets the models to evaluation mode (eval), moves them to the GPU, and calls the test function to perform the testing process."
      ],
      "metadata": {
        "id": "ZURd5mbkQIsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    opt = get_opt()\n",
        "    print(opt)\n",
        "\n",
        "    if not os.path.exists(os.path.join(opt.save_dir, opt.name)):\n",
        "        os.makedirs(os.path.join(opt.save_dir, opt.name))\n",
        "\n",
        "    seg = SegGenerator(opt, input_nc=opt.semantic_nc + 8, output_nc=opt.semantic_nc)\n",
        "    gmm = GMM(opt, inputA_nc=7, inputB_nc=3)\n",
        "    opt.semantic_nc = 7\n",
        "    alias = ALIASGenerator(opt, input_nc=9)\n",
        "    opt.semantic_nc = 13\n",
        "\n",
        "    load_checkpoint(seg, os.path.join(opt.checkpoint_dir, opt.seg_checkpoint))\n",
        "    load_checkpoint(gmm, os.path.join(opt.checkpoint_dir, opt.gmm_checkpoint))\n",
        "    load_checkpoint(alias, os.path.join(opt.checkpoint_dir, opt.alias_checkpoint))\n",
        "\n",
        "    seg.cuda().eval()\n",
        "    gmm.cuda().eval()\n",
        "    alias.cuda().eval()\n",
        "    test(opt, seg, gmm, alias)"
      ],
      "metadata": {
        "id": "cbhxOs70QKZc"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the test and pass in the args"
      ],
      "metadata": {
        "id": "HAwpfy54QM2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.argv[1] = \"--name\" # This line to assign the second arg for example\n",
        "sys.argv[2] = \"test_1\" # This line to assign the third arg for example"
      ],
      "metadata": {
        "id": "Unfld2ZVTYGJ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "asdf"
      ],
      "metadata": {
        "id": "5IvB2X-qTfA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  print(f'CWD: {os.getcwd()}')\n",
        "  os.chdir('/content/VITONHD')\n",
        "  print(f'CWD: {os.getcwd()}')\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVgFtOYzWjDw",
        "outputId": "61e16e26-e62a-49cf-fce4-61dbef6ea49c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CWD: /content/VITONHD\n",
            "CWD: /content/VITONHD\n",
            "Namespace(name='test_1', batch_size=1, workers=1, load_height=1024, load_width=768, shuffle=False, dataset_dir='./datasets/', dataset_mode='test', dataset_list='test_pairs.txt', checkpoint_dir='./checkpoints/', save_dir='./results/', display_freq=1, seg_checkpoint='seg_final.pth', gmm_checkpoint='gmm_final.pth', alias_checkpoint='alias_final.pth', semantic_nc=13, init_type='xavier', init_variance=0.02, grid_size=5, norm_G='spectralaliasinstance', ngf=64, num_upsampling_layers='most')\n",
            "Network [SegGenerator] was created. Total number of parameters: 34.5 million. To see the architecture, do print(network).\n",
            "Network [ALIASGenerator] was created. Total number of parameters: 100.5 million. To see the architecture, do print(network).\n",
            "step: 1\n",
            "step: 2\n",
            "step: 3\n",
            "step: 4\n",
            "step: 5\n",
            "step: 6\n"
          ]
        }
      ]
    }
  ]
}